<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>Cast算子开发 | Kirihara</title><meta name="author" content="Kirihara"><meta name="copyright" content="Kirihara"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Cast算子开发：基于TIR的类型转换算子构建技术解析 摘要 类型转换（Cast）是深度学习框架与编译器中的核心基础算子，负责实现张量在不同数据类型（如FP32→FP16、INT8→FP32）间的精度转换，是模型量化加速、跨层数据兼容的关键组件。本文以一段基于张量中间表示（Tensor Intermediate Representation, TIR）的Cast算子构建代码为研究对象，从技术背景、">
<meta property="og:type" content="article">
<meta property="og:title" content="Cast算子开发">
<meta property="og:url" content="https://kirihara-yun.github.io/2023/12/15/%E7%AE%97%E5%AD%90%E5%BC%80%E5%8F%91/cast/index.html">
<meta property="og:site_name" content="Kirihara">
<meta property="og:description" content="Cast算子开发：基于TIR的类型转换算子构建技术解析 摘要 类型转换（Cast）是深度学习框架与编译器中的核心基础算子，负责实现张量在不同数据类型（如FP32→FP16、INT8→FP32）间的精度转换，是模型量化加速、跨层数据兼容的关键组件。本文以一段基于张量中间表示（Tensor Intermediate Representation, TIR）的Cast算子构建代码为研究对象，从技术背景、">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://kirihara-yun.github.io/img/huiyuanai.png">
<meta property="article:published_time" content="2023-12-15T02:00:00.000Z">
<meta property="article:modified_time" content="2025-10-08T07:36:10.652Z">
<meta property="article:author" content="Kirihara">
<meta property="article:tag" content="算子开发">
<meta property="article:tag" content="Cast">
<meta property="article:tag" content="TIR">
<meta property="article:tag" content="编译器">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://kirihara-yun.github.io/img/huiyuanai.png"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Cast算子开发",
  "url": "https://kirihara-yun.github.io/2023/12/15/%E7%AE%97%E5%AD%90%E5%BC%80%E5%8F%91/cast/",
  "image": "https://kirihara-yun.github.io/img/huiyuanai.png",
  "datePublished": "2023-12-15T02:00:00.000Z",
  "dateModified": "2025-10-08T07:36:10.652Z",
  "author": [
    {
      "@type": "Person",
      "name": "Kirihara",
      "url": "https://kirihara-yun.github.io"
    }
  ]
}</script><link rel="shortcut icon" href="/img/huiyuanai.png"><link rel="canonical" href="https://kirihara-yun.github.io/2023/12/15/%E7%AE%97%E5%AD%90%E5%BC%80%E5%8F%91/cast/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!true && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":150,"languages":{"author":"作者: Kirihara","link":"链接: ","source":"来源: Kirihara","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Cast算子开发',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><meta name="generator" content="Hexo 7.3.0"><link href="https://cdn.bootcss.com/KaTeX/0.11.1/katex.min.css" rel="stylesheet" /></head><body><div id="web_bg" style="background-image: url(/img/fushishan.jpg);"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/img/huiyuanai.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">21</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">44</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">7</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> Movie</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(/img/fushishan.jpg);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><img class="site-icon" src="https://img2.baidu.com/it/u=1933325124,3739680221&amp;fm=253&amp;fmt=auto&amp;app=138&amp;f=JPEG?w=500&amp;h=500" alt="Logo"><span class="site-name">Kirihara</span></a><a class="nav-page-title" href="/"><span class="site-name">Cast算子开发</span><span class="site-name"><i class="fa-solid fa-circle-arrow-left"></i><span>  返回首页</span></span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> Movie</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">Cast算子开发</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-12-15T02:00:00.000Z" title="发表于 2023-12-15 10:00:00">2023-12-15</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-10-08T07:36:10.652Z" title="更新于 2025-10-08 15:36:10">2025-10-08</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E7%AE%97%E5%AD%90%E5%BC%80%E5%8F%91/">算子开发</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">总字数:</span><span class="word-count">3.4k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>11分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><h1>Cast算子开发：基于TIR的类型转换算子构建技术解析</h1>
<h2 id="摘要">摘要</h2>
<p>类型转换（Cast）是深度学习框架与编译器中的核心基础算子，负责实现张量在不同数据类型（如FP32→FP16、INT8→FP32）间的精度转换，是模型量化加速、跨层数据兼容的关键组件。本文以一段基于张量中间表示（Tensor Intermediate Representation, TIR）的Cast算子构建代码为研究对象，从技术背景、代码模块解析、设计亮点与应用场景四个维度，深入剖析算子构建过程中的IR设计、循环调度、图拓扑绑定等核心技术，揭示底层算子开发中“动态形状支持”“数据并行优化”“模块化集成”的实现逻辑，为自定义算子开发与编译器中间表示优化提供参考。</p>
<h2 id="1-引言">1 引言</h2>
<p>在深度学习框架（如TensorFlow、PyTorch）与专用AI编译器（如TVM、MindSpore）中，算子是计算逻辑的最小执行单元，而TIR作为连接算子定义与硬件代码生成的“桥梁”，承担着抽象计算逻辑、支持调度优化的核心角色。类型转换算子看似简单，但其实现需解决三大核心问题：</p>
<ol>
<li><strong>动态形状适配</strong>：如何支持编译时未知的张量维度（如动态Batch Size）；</li>
<li><strong>并行性挖掘</strong>：如何设计循环结构以适配CPU多核、GPU等硬件的并行计算能力；</li>
<li><strong>图拓扑集成</strong>：如何将算子与计算图的输入输出参数绑定，确保数据流向正确性。</li>
</ol>
<p>本文解析的代码正是围绕上述问题展开，实现了一个可复用、高扩展性的Cast算子构建流程，其核心价值在于为自定义TIR算子开发提供了“参数解析→计算定义→调度优化→图集成”的完整模板。</p>
<h2 id="2-技术背景：tir与算子构建流程">2 技术背景：TIR与算子构建流程</h2>
<p>在深入代码前，需明确两个核心概念的定位，为后续解析奠定基础：</p>
<table>
<thead>
<tr>
<th>概念</th>
<th>核心作用</th>
</tr>
</thead>
<tbody>
<tr>
<td>TIR</td>
<td>张量计算的中间表示，抽象了张量元信息（类型、形状）、计算逻辑与调度策略，是代码生成的输入</td>
</tr>
<tr>
<td>OperatorGraph</td>
<td>计算图拓扑结构，记录算子间的依赖关系与数据流向，算子需绑定到图节点以参与端到端执行</td>
</tr>
</tbody>
</table>
<p>算子构建的通用流程可概括为：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">graph TD</span><br><span class="line">    A[参数解析（输入输出类型/形状、图节点信息）] --&gt; B[创建输入占位符张量（TIR层）]</span><br><span class="line">    B --&gt; C[设计循环变量（并行性定义）]</span><br><span class="line">    C --&gt; D[定义计算逻辑（算子核心功能）]</span><br><span class="line">    D --&gt; E[创建调度对象（优化接口预留）]</span><br><span class="line">    E --&gt; F[封装算子函数与图节点]</span><br><span class="line">    F --&gt; G[添加约束（如维度范围）]</span><br><span class="line">    G --&gt; H[绑定算子与计算图参数]</span><br></pre></td></tr></table></figure>
<p>下文代码解析将严格遵循此流程，逐一拆解各环节的实现细节。</p>
<h2 id="3-代码深度解析：cast算子的完整构建过程">3 代码深度解析：Cast算子的完整构建过程</h2>
<p>本节以代码执行流程为线索，逐模块解析实现逻辑，重点说明“为什么这么设计”而非仅“做了什么”，挖掘底层技术考量。</p>
<h3 id="3-1-函数入口与参数初始化">3.1 函数入口与参数初始化</h3>
<p>代码入口函数<code>create_cast_operator</code>接收两个核心参数：<code>TIR&amp; tir</code>（全局TIR上下文，用于存储算子）与<code>FuncParams* FuncParams</code>（算子构建所需的参数集合），首先完成图节点与名称的初始化：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">OperatorGraphFuncNode* <span class="title">create_cast_operator</span><span class="params">(TIR&amp; tir, FuncParams* FuncParams)</span> </span>&#123;</span><br><span class="line">    Node* node = FuncParams-&gt;node;</span><br><span class="line">    string node_name = node-&gt;_simple_name;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 获取输入和输出数据类型</span></span><br><span class="line">    string input_datatype = FuncParams-&gt;input_data_types[<span class="number">0</span>];</span><br><span class="line">    string output_datatype = FuncParams-&gt;output_data_types[<span class="number">0</span>];</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="关键设计解析：">关键设计解析：</h4>
<ol>
<li>
<p><strong>图节点关联（<code>Node* node</code>）</strong>：</p>
<ul>
<li><code>FuncParams-&gt;node</code>指向计算图中的一个节点，<code>node_name</code>从节点的<code>_simple_name</code>获取，确保算子与图节点的“一一对应”，避免拓扑结构混乱。</li>
<li>设计考量：在多算子协作的计算图中，算子名称需与图节点名称一致，否则后续数据流向追踪与调试将无法进行。</li>
</ul>
</li>
<li>
<p><strong>输入输出类型获取</strong>：</p>
<ul>
<li>从<code>FuncParams-&gt;input_data_types[0]</code>与<code>output_data_types[0]</code>分别获取源类型与目标类型（此处假设单输入单输出，可扩展至多输入），这是Cast算子的“核心配置”——决定了转换的精度方向（如<code>float32</code>→<code>float16</code>）。</li>
<li>潜在扩展：若需支持多输入转换（如广播场景下的多张量同精度转换），可通过循环遍历<code>input_data_types</code>实现。</li>
</ul>
</li>
</ol>
<h3 id="3-2-动态形状处理：符号表达式的构建">3.2 动态形状处理：符号表达式的构建</h3>
<p>张量形状是算子的核心元信息，代码中通过“符号表达式”支持编译时未知的动态维度（如NLP任务中的变长序列长度）：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 获取输入形状（支持符号表达式）</span></span><br><span class="line">vector&lt;ScalarExpr&gt; input_shapes_expr;</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">auto</span> dim : FuncParams-&gt;input_shapes[<span class="number">0</span>]) &#123;</span><br><span class="line">    <span class="keyword">if</span> (dim == <span class="number">-1</span>) dim++;  <span class="comment">// 处理动态维度标记（-1→0，符号化表示）</span></span><br><span class="line">    input_shapes_expr.<span class="built_in">push_back</span>(</span><br><span class="line">        <span class="built_in">ScalarExpr</span>(<span class="keyword">new</span> <span class="built_in">Var</span>(<span class="string">&quot;X_dim_&quot;</span> + <span class="built_in">to_string</span>(dim + <span class="number">1</span>), <span class="string">&quot;int32&quot;</span>)));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="关键设计解析：">关键设计解析：</h4>
<ol>
<li>
<p><strong>动态维度标记处理（<code>dim == -1</code>）</strong>：</p>
<ul>
<li>工业界框架中常用<code>-1</code>表示“动态维度”（如PyTorch的<code>torch.randn(-1, 256)</code>），此处<code>dim++</code>将<code>-1</code>转为<code>0</code>，并非改变维度值，而是为后续符号变量命名（如<code>X_dim_1</code>）提供合法索引，避免负号导致的命名异常。</li>
<li>设计考量：动态维度无法在编译时确定，需通过“符号变量（Var）”抽象，而非具体数值，确保算子适配任意合法维度。</li>
</ul>
</li>
<li>
<p><strong>符号形状表达式（<code>ScalarExpr</code>与<code>Var</code>）</strong>：</p>
<ul>
<li>每个维度通过<code>new Var(...)</code>创建符号变量，名称格式为<code>X_dim_&#123;idx&#125;</code>（如第一个维度为<code>X_dim_1</code>），类型为<code>int32</code>（维度值为整数）。</li>
<li>技术价值：符号表达式是TIR支持“动态形状编译”的核心——编译器可基于符号变量进行循环边界分析、内存分配估算（如<code>X_dim_1 * X_dim_2 * sizeof(input_datatype)</code>），无需依赖具体维度数值。</li>
</ul>
</li>
</ol>
<h3 id="3-3-输入张量创建：占位符的抽象表示">3.3 输入张量创建：占位符的抽象表示</h3>
<p>基于上述符号形状，代码创建输入张量<code>X</code>，作为TIR层的抽象输入：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 创建输入张量 X</span></span><br><span class="line">Expr X = <span class="built_in">Expr</span>(<span class="built_in">create_tensor_by_placeholder</span>(<span class="string">&quot;X&quot;</span>, input_datatype,</span><br><span class="line">                                           <span class="built_in">Shape</span>(input_shapes_expr)));</span><br></pre></td></tr></table></figure>
<h4 id="关键设计解析：">关键设计解析：</h4>
<ul>
<li><strong>占位符张量（Placeholder）</strong>：
<ul>
<li><code>create_tensor_by_placeholder</code>函数创建的张量不包含具体数据，仅存储三大元信息：
<ol>
<li>名称（<code>&quot;X&quot;</code>）：用于计算逻辑中引用该张量；</li>
<li>数据类型（<code>input_datatype</code>）：与前文获取的源类型一致；</li>
<li>形状（<code>Shape(input_shapes_expr)</code>）：基于符号表达式的动态形状。</li>
</ol>
</li>
<li>本质：占位符是TIR中“输入端口”的抽象，后续计算逻辑（如Cast）需通过该占位符关联输入数据，确保计算依赖的正确性。</li>
</ul>
</li>
</ul>
<h3 id="3-4-循环变量设计：数据并行的显式定义">3.4 循环变量设计：数据并行的显式定义</h3>
<p>循环是张量计算的核心执行载体，代码中为每个维度创建循环变量，并指定为“数据并行”类型：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 创建循环变量</span></span><br><span class="line">vector&lt;Expr&gt; loopvars;</span><br><span class="line"><span class="keyword">for</span> (<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; input_shapes_expr.<span class="built_in">size</span>(); ++i) &#123;</span><br><span class="line">    loopvars.<span class="built_in">push_back</span>(<span class="built_in">Expr</span>(<span class="built_in">create_loopvar</span>(</span><br><span class="line">        <span class="string">&quot;i&quot;</span> + <span class="built_in">to_string</span>(i),  <span class="comment">// 循环变量名（如i0, i1）</span></span><br><span class="line">        <span class="string">&quot;int32&quot;</span>,             <span class="comment">// 类型</span></span><br><span class="line">        <span class="built_in">Range</span>(<span class="number">0</span>, input_shapes_expr[i]),  <span class="comment">// 范围：[0, 维度大小)</span></span><br><span class="line">        <span class="string">&quot;&quot;</span>, </span><br><span class="line">        LoopVarType::DataPar  <span class="comment">// 数据并行类型</span></span><br><span class="line">    )));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="关键设计解析：">关键设计解析：</h4>
<ol>
<li>
<p><strong>循环变量与维度的映射</strong>：</p>
<ul>
<li>每个维度对应一个循环变量（如2D张量对应<code>i0</code>（行）、<code>i1</code>（列）），循环范围为<code>[0, 维度大小)</code>，与张量的索引逻辑一致（如<code>X[i0][i1]</code>表示2D张量的元素）。</li>
</ul>
</li>
<li>
<p><strong>数据并行类型（<code>LoopVarType::DataPar</code>）</strong>：</p>
<ul>
<li>这是循环设计的核心亮点：<code>DataPar</code>标记表明该循环的迭代可“并行执行”（无数据依赖），编译器可基于此标记进行优化：
<ul>
<li>CPU：自动拆分为多线程，绑定不同核心执行不同迭代；</li>
<li>GPU：映射为线程块（Block）或线程（Thread），利用SIMT架构并行计算；</li>
</ul>
</li>
<li>对比：若为<code>LoopVarType::Seq</code>（串行），则循环需按顺序执行，无法利用硬件并行能力。</li>
</ul>
</li>
</ol>
<h3 id="3-5-计算逻辑定义：cast算子的核心实现">3.5 计算逻辑定义：Cast算子的核心实现</h3>
<p>代码通过<code>create_tensor_by_compute</code>定义输出张量<code>Y</code>，并嵌入Cast计算逻辑：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 执行类型转换操作 Y[i] = cast(X[i], output_datatype)</span></span><br><span class="line">Expr Y = <span class="built_in">Expr</span>(</span><br><span class="line">    <span class="built_in">create_tensor_by_compute</span>(</span><br><span class="line">        <span class="string">&quot;Y&quot;</span>,                  <span class="comment">// 输出张量名</span></span><br><span class="line">        output_datatype,      <span class="comment">// 目标数据类型</span></span><br><span class="line">        <span class="built_in">Shape</span>(input_shapes_expr),  <span class="comment">// 输出形状与输入一致</span></span><br><span class="line">        Expr::<span class="built_in">assign</span>(loopvars, X[loopvars])  <span class="comment">// 计算逻辑</span></span><br><span class="line">    )</span><br><span class="line">);</span><br></pre></td></tr></table></figure>
<h4 id="关键设计解析：">关键设计解析：</h4>
<ol>
<li>
<p><strong>计算张量（Compute Tensor）</strong>：</p>
<ul>
<li>与占位符张量不同，<code>create_tensor_by_compute</code>创建的<code>Y</code>是“计算型张量”，其值由输入张量<code>X</code>与计算逻辑决定，TIR会记录<code>Y</code>与<code>X</code>的依赖关系（<code>Y</code>依赖<code>X</code>）。</li>
</ul>
</li>
<li>
<p><strong>Cast逻辑的隐式表达</strong>：</p>
<ul>
<li>代码中<code>X[loopvars]</code>表示“输入张量在当前循环索引下的元素”，<code>Expr::assign(loopvars, X[loopvars])</code>看似是“赋值”，实则隐含了“类型转换”——因为<code>Y</code>的目标类型（<code>output_datatype</code>）与<code>X</code>的源类型（<code>input_datatype</code>）不同，TIR会在代码生成阶段自动插入类型转换指令（如CPU的<code>cvttss2si</code>、GPU的<code>cvt.f32.f16</code>）。</li>
<li>设计考量：通过“张量类型差异”隐式触发Cast，避免显式编写转换函数，简化代码同时保证兼容性（不同硬件的转换指令由TIR统一处理）。</li>
</ul>
</li>
</ol>
<h3 id="3-6-调度对象创建：优化接口的预留">3.6 调度对象创建：优化接口的预留</h3>
<p>调度（Schedule）是TIR中“性能优化”的入口，代码为<code>Y</code>的计算操作创建调度对象：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 创建调度</span></span><br><span class="line">Schedule* schedule = <span class="built_in">create_schedule</span>(Y.<span class="built_in">get_tensor</span>()-&gt;op);</span><br></pre></td></tr></table></figure>
<h4 id="关键设计解析：">关键设计解析：</h4>
<ul>
<li><strong>调度的作用</strong>：
<ul>
<li><code>Y.get_tensor()-&gt;op</code>指向<code>Y</code>的计算操作（即Cast），<code>create_schedule</code>为该操作创建调度对象，后续可通过该对象添加优化策略：
<ul>
<li>循环展开（Loop Unrolling）：减少循环控制开销；</li>
<li>循环融合（Loop Fusion）：若后续有算子依赖<code>Y</code>，可将多循环融合为一个，减少内存访问；</li>
<li>内存布局优化（如将NHWC转为NCHW，适配GPU纹理内存）；</li>
</ul>
</li>
<li>代码中未显式添加优化，而是预留调度接口，体现“模块化设计”——算子逻辑与优化策略分离，便于后续根据硬件特性调整调度。</li>
</ul>
</li>
</ul>
<h3 id="3-7-算子与图节点封装：逻辑与拓扑的绑定">3.7 算子与图节点封装：逻辑与拓扑的绑定</h3>
<p>代码将计算逻辑（调度）与图节点封装，确保算子可被计算图调用：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 创建算子函数和图节点</span></span><br><span class="line">OperatorFunc* cast_func = <span class="keyword">new</span> <span class="built_in">OperatorFunc</span>(node_name, schedule);</span><br><span class="line">OperatorGraphFuncNode* cast_node = <span class="keyword">new</span> <span class="built_in">OperatorGraphFuncNode</span>(node_name, <span class="string">&quot;params_none&quot;</span>);</span><br></pre></td></tr></table></figure>
<h4 id="关键设计解析：">关键设计解析：</h4>
<ul>
<li><strong>双对象分离设计</strong>：
<ul>
<li><code>OperatorFunc</code>：封装算子的“计算逻辑”与“调度策略”，是代码生成的核心单元；</li>
<li><code>OperatorGraphFuncNode</code>：封装算子在计算图中的“拓扑信息”（名称、参数标记），是图拓扑的组成单元；</li>
<li>设计优势：解耦计算逻辑与拓扑结构，若需复用Cast逻辑到不同图节点，仅需创建新的<code>OperatorGraphFuncNode</code>，无需重复定义<code>OperatorFunc</code>。</li>
</ul>
</li>
</ul>
<h3 id="3-8-未知变量约束：正确性与优化的保障">3.8 未知变量约束：正确性与优化的保障</h3>
<p>代码为符号维度变量添加范围约束，避免无效维度导致的计算错误：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 添加未知变量范围约束</span></span><br><span class="line"><span class="keyword">for</span> (<span class="type">const</span> <span class="keyword">auto</span>&amp; expr : input_shapes_expr) &#123;</span><br><span class="line">    cast_func-&gt;unknown_var_bound[expr.node-&gt;<span class="built_in">as</span>&lt;ExprVarNode&gt;()-&gt;var] =</span><br><span class="line">        <span class="built_in">Range</span>(<span class="number">1</span>, MAX_INF - <span class="number">1</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="关键设计解析：">关键设计解析：</h4>
<ul>
<li><strong>约束的必要性</strong>：
<ul>
<li>符号变量（如<code>X_dim_1</code>）的范围若不限制，可能出现<code>0</code>或负维度（如<code>X_dim_1=0</code>将导致张量无元素，<code>X_dim_1=-2</code>为非法值），引发内存分配失败或计算空指针；</li>
<li>约束<code>Range(1, MAX_INF - 1)</code>确保维度为“正整数”，同时<code>MAX_INF - 1</code>避免溢出（兼容不同硬件的最大维度限制）；</li>
<li>技术价值：约束为编译器的“静态分析”提供依据，如内存分配时可确定“最小内存需求为<code>1 * sizeof(output_datatype)</code>”，避免过度分配。</li>
</ul>
</li>
</ul>
<h3 id="3-9-算子与图参数连接：数据流向的闭环">3.9 算子与图参数连接：数据流向的闭环</h3>
<p>最后，代码将算子节点与计算图的输出参数绑定，完成数据流向的闭环：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 连接算子到图中的输出参数</span></span><br><span class="line">ConnectOperatorToGraphParams* connect_params = <span class="keyword">new</span> <span class="built_in">ConnectOperatorToGraphParams</span>();</span><br><span class="line">connect_params-&gt;node_name = node_name;          <span class="comment">// 关联图节点</span></span><br><span class="line">connect_params-&gt;output_datatype = output_datatype;  <span class="comment">// 输出类型</span></span><br><span class="line">connect_params-&gt;output_name = node-&gt;_outputs_name[<span class="number">0</span>];  <span class="comment">// 输出名称</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">connect_operator_to_graph</span>(tir, connect_params, cast_node);</span><br></pre></td></tr></table></figure>
<h4 id="关键设计解析：">关键设计解析：</h4>
<ul>
<li><strong>连接参数的作用</strong>：
<ul>
<li><code>connect_params</code>封装了“算子→图”的绑定信息，核心是<code>output_name = node-&gt;_outputs_name[0]</code>——将算子的输出<code>Y</code>与图节点的输出端口名称关联，确保计算结果能传递到下一个算子的输入；</li>
<li><code>connect_operator_to_graph</code>函数是“胶水接口”，负责将<code>cast_node</code>（算子图节点）注册到<code>TIR</code>上下文，并更新计算图的拓扑依赖；</li>
<li>示例：若下一个算子是<code>Add</code>，其输入名称需与<code>node-&gt;_outputs_name[0]</code>一致，才能正确接收Cast算子的输出。</li>
</ul>
</li>
</ul>
<h2 id="4-核心设计亮点总结">4 核心设计亮点总结</h2>
<p>基于上述解析，该Cast算子代码的设计亮点可概括为以下五点，为自定义算子开发提供参考：</p>
<table>
<thead>
<tr>
<th>设计亮点</th>
<th>技术实现</th>
<th>核心价值</th>
</tr>
</thead>
<tbody>
<tr>
<td>动态形状支持</td>
<td>符号变量（Var）+  scalarExpr</td>
<td>适配动态Batch、变长序列等场景，提升通用性</td>
</tr>
<tr>
<td>数据并行显式化</td>
<td>LoopVarType::DataPar</td>
<td>为硬件并行优化提供标记，提升执行效率</td>
</tr>
<tr>
<td>逻辑与拓扑解耦</td>
<td>OperatorFunc与OperatorGraphFuncNode分离</td>
<td>算子逻辑可复用，降低开发成本</td>
</tr>
<tr>
<td>约束驱动的正确性保障</td>
<td>未知变量范围约束</td>
<td>避免非法维度，为静态分析与优化提供依据</td>
</tr>
<tr>
<td>模块化连接接口</td>
<td>ConnectOperatorToGraphParams</td>
<td>标准化算子与图的绑定流程，降低集成复杂度</td>
</tr>
</tbody>
</table>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://kirihara-yun.github.io">Kirihara</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://kirihara-yun.github.io/2023/12/15/%E7%AE%97%E5%AD%90%E5%BC%80%E5%8F%91/cast/">https://kirihara-yun.github.io/2023/12/15/%E7%AE%97%E5%AD%90%E5%BC%80%E5%8F%91/cast/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="https://kirihara-yun.github.io" target="_blank">Kirihara</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E7%AE%97%E5%AD%90%E5%BC%80%E5%8F%91/">算子开发</a><a class="post-meta__tags" href="/tags/Cast/">Cast</a><a class="post-meta__tags" href="/tags/TIR/">TIR</a><a class="post-meta__tags" href="/tags/%E7%BC%96%E8%AF%91%E5%99%A8/">编译器</a></div><div class="post-share"><div class="social-share" data-image="/img/huiyuanai.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2023/12/15/%E7%AE%97%E5%AD%90%E5%BC%80%E5%8F%91/concat/" title="Concat算子开发"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">Concat算子开发</div></div><div class="info-2"><div class="info-item-1">深度学习框架中Concat算子的TIR构建与实现：从理论到代码 摘要 张量拼接（Concat）作为深度学习框架中最基础的算子之一，承担着多输入张量在指定维度上融合的核心功能。本文基于TIR（Tensor Intermediate Representation）中间表示，详细阐述Concat算子的构建流程，包括输入合法性校验、维度处理、符号计算图生成及调度优化等关键技术点。通过解析算子实现的底层逻辑，揭示深度学习框架中算子设计的通用性原则，为自定义算子开发提供方法论参考。 引言 在深度学习模型中，张量的维度操作是构建复杂网络结构的基础。Concat算子通过在指定维度上拼接多个同秩张量，实现特征融合或维度扩展，广泛应用于残差连接、多尺度特征融合等场景。与Element-wise算子相比，Concat算子的实现需重点解决维度一致性校验、动态索引计算和符号形状推理三大核心问题。 本文基于某深度学习框架的TIR中间表示，从代码实现角度剖析Concat算子的构建过程。通过对输入校验、轴处理、计算图生成等模块的逐段解析，展现算子从抽象定义到具体执行的完整映射过程，并探讨其在性能优化中的潜在方向...</div></div></div></a><a class="pagination-related" href="/2023/10/20/transformer/%E7%BC%96%E7%A0%81%E5%99%A8%E4%B8%8E%E8%A7%A3%E7%A0%81%E5%99%A8/" title="Transformer编码器-解码器双向协作模式：原理、设计与优化"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">Transformer编码器-解码器双向协作模式：原理、设计与优化</div></div><div class="info-2"><div class="info-item-1">编码器-解码器双向协作模式：原理、设计、问题与解决方案 1. 引言：Transformer与编码器-解码器框架概述 自2017年Google团队在《Attention Is All You Need》中提出Transformer模型以来，其基于“注意力机制”的核心设计彻底改变了自然语言处理（NLP）、计算机视觉（CV）等领域的序列建模范式。Transformer的核心架构由编码器（Encoder） 和解码器（Decoder） 两部分组成，二者通过注意力机制实现信息交互，是机器翻译、文本摘要、对话生成等“序列到序列（Seq2Seq）”任务的核心载体。 在传统Seq2Seq模型（如RNN-based）中，编码器仅负责将输入序列编码为固定长度的“上下文向量”，再传递给解码器生成输出序列——这种“单向信息流动”模式在长序列或复杂任务中存在明显局限。随着研究推进，编码器-解码器双向协作模式逐渐成为主流：它打破了“编码器一次性输出、解码器被动接收”的限制，实现了编码器与解码器在生成过程中的动态信息交互（编码器根据解码器的当前状态调整输出，解码器根据编码器的动态反馈优化生成），显著提升了模型对...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2023/12/15/%E7%AE%97%E5%AD%90%E5%BC%80%E5%8F%91/concat/" title="Concat算子开发"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2023-12-15</div><div class="info-item-2">Concat算子开发</div></div><div class="info-2"><div class="info-item-1">深度学习框架中Concat算子的TIR构建与实现：从理论到代码 摘要 张量拼接（Concat）作为深度学习框架中最基础的算子之一，承担着多输入张量在指定维度上融合的核心功能。本文基于TIR（Tensor Intermediate Representation）中间表示，详细阐述Concat算子的构建流程，包括输入合法性校验、维度处理、符号计算图生成及调度优化等关键技术点。通过解析算子实现的底层逻辑，揭示深度学习框架中算子设计的通用性原则，为自定义算子开发提供方法论参考。 引言 在深度学习模型中，张量的维度操作是构建复杂网络结构的基础。Concat算子通过在指定维度上拼接多个同秩张量，实现特征融合或维度扩展，广泛应用于残差连接、多尺度特征融合等场景。与Element-wise算子相比，Concat算子的实现需重点解决维度一致性校验、动态索引计算和符号形状推理三大核心问题。 本文基于某深度学习框架的TIR中间表示，从代码实现角度剖析Concat算子的构建过程。通过对输入校验、轴处理、计算图生成等模块的逐段解析，展现算子从抽象定义到具体执行的完整映射过程，并探讨其在性能优化中的潜在方向...</div></div></div></a><a class="pagination-related" href="/2023/08/01/%E7%AE%97%E5%AD%90%E5%BC%80%E5%8F%91/add/" title="算子开发-add"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2023-08-01</div><div class="info-item-2">算子开发-add</div></div><div class="info-2"><div class="info-item-1">算子开发-add 在深度学习框架或数值计算引擎中，Add（加法）算子是最基础、最常用的计算单元之一。它看似简单，却需要兼顾输入兼容性（如张量广播）、数据类型安全、内存稳定性等核心问题。本文将详细拆解Add算子的实现逻辑，从需求分析到代码落地，剖析基础算子开发的关键设计思路。 开发背景与核心需求 Add算子的核心功能是实现两个张量（或标量）的逐元素加法，但在实际框架中，其需满足以下工程化需求：  输入合法性校验：避免空指针、输入数量不足（至少2个输入）、形状/数据类型信息缺失等问题导致崩溃； 张量广播支持：兼容不同维度的输入（如[2,3]与[3]相加），按广播规则推导输出形状； 数据类型安全：仅支持框架适配的数值类型（如float32/float64/int32/int64），拒绝非法类型； 内存安全：避免内存泄漏、野指针访问，确保动态分配的资源（如Var、Schedule）正确释放； 符号维度管理：支持动态维度（如-1表示未知维度），并通过约束保证输出维度的合法性。  核心设计思路 在具体实现前，需梳理Add算子的核心流程以确保逻辑闭环：  前置校验：先执行安全检查（空指针、输入...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/huiyuanai.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">Kirihara</div><div class="author-info-description">喜欢您来</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">21</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">44</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">7</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/Kirihara-Yun"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/Kirihara-Yun" target="_blank" title=""><i class="fab fa-github"></i></a><a class="social-icon" href="/qinzhy26@mail2.sysu.edu.cn" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #000000;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">希望您天天开心</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-text">Cast算子开发：基于TIR的类型转换算子构建技术解析</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%91%98%E8%A6%81"><span class="toc-text">摘要</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E5%BC%95%E8%A8%80"><span class="toc-text">1 引言</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E6%8A%80%E6%9C%AF%E8%83%8C%E6%99%AF%EF%BC%9Atir%E4%B8%8E%E7%AE%97%E5%AD%90%E6%9E%84%E5%BB%BA%E6%B5%81%E7%A8%8B"><span class="toc-text">2 技术背景：TIR与算子构建流程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-%E4%BB%A3%E7%A0%81%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90%EF%BC%9Acast%E7%AE%97%E5%AD%90%E7%9A%84%E5%AE%8C%E6%95%B4%E6%9E%84%E5%BB%BA%E8%BF%87%E7%A8%8B"><span class="toc-text">3 代码深度解析：Cast算子的完整构建过程</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-%E5%87%BD%E6%95%B0%E5%85%A5%E5%8F%A3%E4%B8%8E%E5%8F%82%E6%95%B0%E5%88%9D%E5%A7%8B%E5%8C%96"><span class="toc-text">3.1 函数入口与参数初始化</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%B3%E9%94%AE%E8%AE%BE%E8%AE%A1%E8%A7%A3%E6%9E%90%EF%BC%9A"><span class="toc-text">关键设计解析：</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-%E5%8A%A8%E6%80%81%E5%BD%A2%E7%8A%B6%E5%A4%84%E7%90%86%EF%BC%9A%E7%AC%A6%E5%8F%B7%E8%A1%A8%E8%BE%BE%E5%BC%8F%E7%9A%84%E6%9E%84%E5%BB%BA"><span class="toc-text">3.2 动态形状处理：符号表达式的构建</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%B3%E9%94%AE%E8%AE%BE%E8%AE%A1%E8%A7%A3%E6%9E%90%EF%BC%9A"><span class="toc-text">关键设计解析：</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-%E8%BE%93%E5%85%A5%E5%BC%A0%E9%87%8F%E5%88%9B%E5%BB%BA%EF%BC%9A%E5%8D%A0%E4%BD%8D%E7%AC%A6%E7%9A%84%E6%8A%BD%E8%B1%A1%E8%A1%A8%E7%A4%BA"><span class="toc-text">3.3 输入张量创建：占位符的抽象表示</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%B3%E9%94%AE%E8%AE%BE%E8%AE%A1%E8%A7%A3%E6%9E%90%EF%BC%9A"><span class="toc-text">关键设计解析：</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-4-%E5%BE%AA%E7%8E%AF%E5%8F%98%E9%87%8F%E8%AE%BE%E8%AE%A1%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%B9%B6%E8%A1%8C%E7%9A%84%E6%98%BE%E5%BC%8F%E5%AE%9A%E4%B9%89"><span class="toc-text">3.4 循环变量设计：数据并行的显式定义</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%B3%E9%94%AE%E8%AE%BE%E8%AE%A1%E8%A7%A3%E6%9E%90%EF%BC%9A"><span class="toc-text">关键设计解析：</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-5-%E8%AE%A1%E7%AE%97%E9%80%BB%E8%BE%91%E5%AE%9A%E4%B9%89%EF%BC%9Acast%E7%AE%97%E5%AD%90%E7%9A%84%E6%A0%B8%E5%BF%83%E5%AE%9E%E7%8E%B0"><span class="toc-text">3.5 计算逻辑定义：Cast算子的核心实现</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%B3%E9%94%AE%E8%AE%BE%E8%AE%A1%E8%A7%A3%E6%9E%90%EF%BC%9A"><span class="toc-text">关键设计解析：</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-6-%E8%B0%83%E5%BA%A6%E5%AF%B9%E8%B1%A1%E5%88%9B%E5%BB%BA%EF%BC%9A%E4%BC%98%E5%8C%96%E6%8E%A5%E5%8F%A3%E7%9A%84%E9%A2%84%E7%95%99"><span class="toc-text">3.6 调度对象创建：优化接口的预留</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%B3%E9%94%AE%E8%AE%BE%E8%AE%A1%E8%A7%A3%E6%9E%90%EF%BC%9A"><span class="toc-text">关键设计解析：</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-7-%E7%AE%97%E5%AD%90%E4%B8%8E%E5%9B%BE%E8%8A%82%E7%82%B9%E5%B0%81%E8%A3%85%EF%BC%9A%E9%80%BB%E8%BE%91%E4%B8%8E%E6%8B%93%E6%89%91%E7%9A%84%E7%BB%91%E5%AE%9A"><span class="toc-text">3.7 算子与图节点封装：逻辑与拓扑的绑定</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%B3%E9%94%AE%E8%AE%BE%E8%AE%A1%E8%A7%A3%E6%9E%90%EF%BC%9A"><span class="toc-text">关键设计解析：</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-8-%E6%9C%AA%E7%9F%A5%E5%8F%98%E9%87%8F%E7%BA%A6%E6%9D%9F%EF%BC%9A%E6%AD%A3%E7%A1%AE%E6%80%A7%E4%B8%8E%E4%BC%98%E5%8C%96%E7%9A%84%E4%BF%9D%E9%9A%9C"><span class="toc-text">3.8 未知变量约束：正确性与优化的保障</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%B3%E9%94%AE%E8%AE%BE%E8%AE%A1%E8%A7%A3%E6%9E%90%EF%BC%9A"><span class="toc-text">关键设计解析：</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-9-%E7%AE%97%E5%AD%90%E4%B8%8E%E5%9B%BE%E5%8F%82%E6%95%B0%E8%BF%9E%E6%8E%A5%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%B5%81%E5%90%91%E7%9A%84%E9%97%AD%E7%8E%AF"><span class="toc-text">3.9 算子与图参数连接：数据流向的闭环</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%B3%E9%94%AE%E8%AE%BE%E8%AE%A1%E8%A7%A3%E6%9E%90%EF%BC%9A"><span class="toc-text">关键设计解析：</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-%E6%A0%B8%E5%BF%83%E8%AE%BE%E8%AE%A1%E4%BA%AE%E7%82%B9%E6%80%BB%E7%BB%93"><span class="toc-text">4 核心设计亮点总结</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/10/06/transformer/%E5%B1%82%E5%BD%92%E4%B8%80%E5%8C%96%E4%BD%8D%E7%BD%AE%E9%80%89%E6%8B%A9/" title="层归一化位置选择">层归一化位置选择</a><time datetime="2025-10-06T02:00:00.000Z" title="发表于 2025-10-06 10:00:00">2025-10-06</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/09/25/%E5%8A%9B%E6%89%A3%E5%88%B7%E9%A2%98/372%E8%B6%85%E7%BA%A7%E6%AC%A1%E6%96%B9/" title="372超级次方">372超级次方</a><time datetime="2025-09-24T16:00:00.000Z" title="发表于 2025-09-25 00:00:00">2025-09-25</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/09/25/%E5%8A%9B%E6%89%A3%E5%88%B7%E9%A2%98/436%E5%AF%BB%E6%89%BE%E5%8F%B3%E5%8C%BA%E9%97%B4/" title="436寻找右区间">436寻找右区间</a><time datetime="2025-09-24T16:00:00.000Z" title="发表于 2025-09-25 00:00:00">2025-09-25</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/09/20/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/memag/" title="MEMAGmemory-Efficient Graph Transformation via Access Pattern-Aware Optimization for DNNs">MEMAGmemory-Efficient Graph Transformation via Access Pattern-Aware Optimization for DNNs</a><time datetime="2025-09-20T08:00:00.000Z" title="发表于 2025-09-20 16:00:00">2025-09-20</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/09/18/%E5%8A%9B%E6%89%A3%E5%88%B7%E9%A2%98/318%E6%9C%80%E5%A4%A7%E5%8D%95%E8%AF%8D%E9%95%BF%E5%BA%A6%E4%B9%98%E7%A7%AF/" title="318. 最大单词长度乘积">318. 最大单词长度乘积</a><time datetime="2025-09-18T02:00:00.000Z" title="发表于 2025-09-18 10:00:00">2025-09-18</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url(/img/fushishan.jpg);"><div class="footer-other"><div class="footer-copyright"><span class="copyright">&copy;&nbsp;2025 By Kirihara</span></div><div class="footer_custom_text">你终于找到我啦(*^▽^*)</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><div class="js-pjax"></div><script src="https://cdn.jsdelivr.net/npm/pjax/pjax.min.js"></script><script>(() => {
  const pjaxSelectors = ["head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]

  window.pjax = new Pjax({
    elements: 'a:not([target="_blank"])',
    selectors: pjaxSelectors,
    cacheBust: false,
    analytics: false,
    scrollRestoration: false
  })

  const triggerPjaxFn = (val) => {
    if (!val) return
    Object.values(val).forEach(fn => {
      try {
        fn()
      } catch (err) {
        console.debug('Pjax callback failed:', err)
      }
    })
  }

  document.addEventListener('pjax:send', () => {
    // removeEventListener
    btf.removeGlobalFnEvent('pjaxSendOnce')
    btf.removeGlobalFnEvent('themeChange')

    // reset readmode
    const $bodyClassList = document.body.classList
    if ($bodyClassList.contains('read-mode')) $bodyClassList.remove('read-mode')

    triggerPjaxFn(window.globalFn.pjaxSend)
  })

  document.addEventListener('pjax:complete', () => {
    btf.removeGlobalFnEvent('pjaxCompleteOnce')
    document.querySelectorAll('script[data-pjax]').forEach(item => {
      const newScript = document.createElement('script')
      const content = item.text || item.textContent || item.innerHTML || ""
      Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
      newScript.appendChild(document.createTextNode(content))
      item.parentNode.replaceChild(newScript, item)
    })

    triggerPjaxFn(window.globalFn.pjaxComplete)
  })

  document.addEventListener('pjax:error', e => {
    if (e.request.status === 404) {
      const usePjax = true
      true
        ? (usePjax ? pjax.loadUrl('/404.html') : window.location.href = '/404.html')
        : window.location.href = e.request.responseURL
    }
  })
})()</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>